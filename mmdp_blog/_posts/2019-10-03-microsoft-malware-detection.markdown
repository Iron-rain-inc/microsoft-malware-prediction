---
layout: post
title:  "Microsoft Malware Detection!"
date:   2019-03-10 11:59:13 +1100
categories: jekyll update
---

![airplane](../../../../../assets/malware_blog/malicious-code-4036349_960_720.jpg)
 

# Welcome
This report details the effor to create a model for detection of malware vulnerable Microsoft computers. 
The report has been broken down into the sections below for ease of reading and a complete Jupyter Notebook report can be found here. 

<details><summary><strong>Business Understanding</strong></summary>
    <p>
        <br>
        <strong>Project Introduction</strong>
        <br>
        Microsoft have engaged data scientists world wide to develop a model for the purpose of detecting malware vulnerable computers.<br><br>
        The intent of this project is to develop a model using the Microsoft provided dataset, this model will be trained and then implemented on provided testing data. 
        <br><br>
        <strong>Problem Statement</strong> 
        <br>
        Malware is an issue within any computing society, billions of computer around the world are vulnerable. Malware infection is a preventable problem that can be solved, on one facet, by predicting an attack prior to it happening.<br><br>
        Using the provided dataset this project will construct a model that will predict computer vulerability to a malware attack. This information could then be used for a vendor or customer to perform preventative action.
        <br><br>
        <strong>Project Overview</strong>
        <br>
        This project will use the Microsoft LightGBM model to train and predict answers with. The LightGBM model is a gradient boosting framework based on decision tree algorithms. <br><br>
        The initial sessions for this project made use of the sckit-learn DecisionTreeClassifier and AdaBoost models, the performance in both speed and accuracy was not achieving the desired levels and multiple other models were tested.<br><br>
        LightGBM became the choice for this project as it is, comparatively, extremely quick to train a model and offered inbuil GPU support to increase that time further. 
        <br><br>
        The end product is a machine learning model and as such machine learning metrics will be used to determine the success of the project.<br><br>
        The following measurements will be used to evaulate the model:
        <ul>
            <li>Confusion Matrix</li>
            <li>Accuracy Score</li>
            <li>F1 Score</li>
            <li>Precision Score</li>
            <li>Recall Score</li>
        </ul>
    </p>
</details>

<br>

<details><summary><strong>Data Understanding and Preprocessing</strong></summary>
    <p>
        <br>
        <strong>Data Overview</strong>
        <br>
        The dataset provided for model training is provided by Microsoft and Kaggle for a Kaggle Competition. 
        <br>It can be found at the Kaggle Competition <a href="https://www.kaggle.com/c/microsoft-malware-prediction/data">page</a>.
        <br><br>
        Within the dataset, each row corresponds to a unique machine, these can be servers, computer, phones, tablets and other various devices accross all branches of the Microsoft Windows operating systems.<br><br>
        The <span markdown="1">`MachineIdentifier`</span> column is used to uniquely identify each machine and the <span markdown="1">`HasDetections`</span> to indicate whether or not a computer has a malware event detected on it. The remaining data points are the states and versions of related Microsoft components on each machine. <br><br>
        The data is sourced froma variety of malware machines and does not just represent Microsoft customer machines. <br><br>
        An excerpt from the competition page <i>"The sampling methodology used to create this dataset was designed to meet certain business constraints, both in regards to user privacy as well as the time period during which the machine was running."</i> explains the sampling methodology used for this data. 
    <br><br>
    <strong>Data Discovery</strong>
    <br>
    Data discovery for this project is an iterative process mixed in with the data preprocesing, this part of the report will hilight the discovery techniques used, if you would like to see the full sequence please view the Notebook.<br><br>
        <i><b>Initial Data</b></i>
        <br>
        Upon loading the data the first two pieces of information required were the column type breakdown and the missing data reports. <br>
        <table>
          <tr>
            <th>Missing Values</th>
            <th>Data Types</th>
          </tr>
          <tr>
            <td><span markdown="1">![missing_vals](../../../../../assets/malware_blog/output_16_1.png)</span></td>
            <td><span markdown="1">![datatypes](../../../../../assets/malware_blog/output_36_1.png)</span></td>
          </tr>
        </table>
        <i>Missing Values</i>
    <br>
    Missing data requires either removal from the dataset or substitution prior to any modelling occuring. <br><br>
    For the dataset in use, less than 10% data missing in a column has been deemed trivial, the colums missing greater than this are shown:<br><br>
    <table border="1" class="dataframe">
      <thead>
        <tr style="text-align: right;">
          <th></th>
          <th>Missing Percentage</th>
        </tr>
      </thead>
      <tbody>
        <tr>
          <th>DefaultBrowsersIdentifier</th>
          <td>95.141637</td>
        </tr>
        <tr>
          <th>OrganizationIdentifier</th>
          <td>30.841487</td>
        </tr>
        <tr>
          <th>PuaMode</th>
          <td>99.974119</td>
        </tr>
        <tr>
          <th>SmartScreen</th>
          <td>35.610795</td>
        </tr>
        <tr>
          <th>Census_ProcessorClass</th>
          <td>99.589407</td>
        </tr>
        <tr>
          <th>Census_InternalBatteryType</th>
          <td>71.046809</td>
        </tr>
        <tr>
          <th>Census_IsFlightingInternal</th>
          <td>83.044030</td>
        </tr>
        <tr>
          <th>Census_ThresholdOptIn</th>
          <td>63.524472</td>
        </tr>
        <tr>
          <th>Census_IsWIMBootEnabled</th>
          <td>63.439038</td>
        </tr>
      </tbody>
    </table>
    From this brief look at the missing data it is determined that <span markdown="1">`DefaultBrowserIdentifier`</span>, <span markdown="1">`Census_ProcessorClass`</span> & <span markdown="1">`PuaMode`</span> can be dropped as there is no feasible way to keep them.<br><br>
    The next steps are to review the remaining fields to determine if they are worth keeping. The Kaggle competition data page provides a brief insight into some of the fields meanings but further investigation was warranted.<br> 
        <ul>
            <li><span markdown="1">`OrganizationIdentifier` - ID for the organization the machine belongs in, organization ID is mapped to both specific companies and broad industries.</span></li>
            <li><span markdown="1">`SmartScreen` - A cloud-based anti-phishing and anti-malware component.</span></li>
            <li><span markdown="1">`Census_InternalBatteryType` - Internal battery type</span></li>
            <li><span markdown="1">`Census_IsFlightingInternal` - Related to OS releases</span></li>
            <li><span markdown="1">`Census_ThresholdOptIn` - NA</span></li>
            <li><span markdown="1">`Census_IsWIMBootEnabled` - Allows a Windows image to be compressed, reducing usage space.</span></li>
        </ul>
    Of the fields listed above the <span markdown="1">`SmartScreen`</span> column leaps out as important, the <span markdown="1">`SmartScreen`</span> column will be kept by dropping all rows with missing values.<br>
    <br>
    The dataset provided also has a number of fields that repeat data, whether in whole or sections of another column. The tool used to discover this is correlation and the chart can be seen below.<br><br>
    Note, many of the columns below could not be correlated until after label encoding has taken place, this is preprocessing step that will be described later.<br>
    <span markdown="1">![missing_vals](../../../../../assets/malware_blog/output_43_0.png)</span>          
    <br>
    As can be seen by the chart above there are a few columns with very high correlation values. These value require further investigation, the table below shows all columns with a correlation of 0.9 or higher. <br>
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th></th>
      <th>Correlation</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>EngineVersion</th>
      <th>AvSigVersion</th>
      <td>0.901399</td>
    </tr>
    <tr>
      <th>AvSigVersion</th>
      <th>EngineVersion</th>
      <td>0.901399</td>
    </tr>
    <tr>
      <th>Platform</th>
      <th>OsVer</th>
      <td>0.999470</td>
    </tr>
    <tr>
      <th>Processor</th>
      <th>Census_OSArchitecture</th>
      <td>0.995984</td>
    </tr>
    <tr>
      <th>OsVer</th>
      <th>Platform</th>
      <td>0.999470</td>
    </tr>
    <tr>
      <th>OsBuildLab</th>
      <th>IeVerIdentifier</th>
      <td>0.951463</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">SkuEdition</th>
      <th>Census_OSEdition</th>
      <td>0.920566</td>
    </tr>
    <tr>
      <th>Census_OSSkuName</th>
      <td>0.906636</td>
    </tr>
    <tr>
      <th>IeVerIdentifier</th>
      <th>OsBuildLab</th>
      <td>0.951463</td>
    </tr>
    <tr>
      <th>Census_OSVersion</th>
      <th>Census_OSBuildNumber</th>
      <td>0.985123</td>
    </tr>
    <tr>
      <th>Census_OSArchitecture</th>
      <th>Processor</th>
      <td>0.995984</td>
    </tr>
    <tr>
      <th>Census_OSBuildNumber</th>
      <th>Census_OSVersion</th>
      <td>0.985123</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Census_OSEdition</th>
      <th>SkuEdition</th>
      <td>0.920566</td>
    </tr>
    <tr>
      <th>Census_OSSkuName</th>
      <td>0.998320</td>
    </tr>
    <tr>
      <th rowspan="2" valign="top">Census_OSSkuName</th>
      <th>SkuEdition</th>
      <td>0.906636</td>
    </tr>
    <tr>
      <th>Census_OSEdition</th>
      <td>0.998320</td>
    </tr>
    <tr>
      <th>Census_OSInstallLanguageIdentifier</th>
      <th>Census_OSUILocaleIdentifier</th>
      <td>0.990449</td>
    </tr>
    <tr>
      <th>Census_OSUILocaleIdentifier</th>
      <th>Census_OSInstallLanguageIdentifier</th>
      <td>0.990449</td>
    </tr>
  </tbody>
</table>
    The next step is to determine which of the columns are repitition data and can be dropped, this is done through by comparing the value_counts() of each column.<br><br> 
    The following cells have been identified to be dropped during preprocessing; <span markdown="1">`SkuEdition`</span>, <span markdown="1">`Census_OSSkuName`</span>, <span markdown="1">`OsBuild`</span>, <span markdown="1">`Census_OSBuildNumber`</span>, <span markdown="1">`Processor`</span>, <span markdown="1">`Platform`</span>                
    <br>
    At this point the initial data discovery is complete and preprocessing can begin. 
    <br>
    <br>    
    <strong>Data Preprocessing</strong>
    <br>
    Continuing on from dropping the missing rows of <span markdown="1">`SmartScreen`</span>.
    The table below is how the missing data has changed:
    <table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Missing Percentage</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>DefaultBrowsersIdentifier</th>
      <td>95.223947</td>
    </tr>
    <tr>
      <th>OrganizationIdentifier</th>
      <td>31.069661</td>
    </tr>
    <tr>
      <th>PuaMode</th>
      <td>99.974445</td>
    </tr>
    <tr>
      <th>Census_ProcessorClass</th>
      <td>99.471318</td>
    </tr>
    <tr>
      <th>Census_InternalBatteryType</th>
      <td>55.826906</td>
    </tr>
    <tr>
      <th>Census_IsFlightingInternal</th>
      <td>74.104113</td>
    </tr>
    <tr>
      <th>Census_ThresholdOptIn</th>
      <td>44.585629</td>
    </tr>
    <tr>
      <th>Census_IsWIMBootEnabled</th>
      <td>44.455400</td>
    </tr>
  </tbody>
</table>
    There have been no drastic changes in the data caused by the removal of the missing values for <span markdown="1">`SmartScreen`</span>.<br><br>
    The other field that is of interest is the <span markdown="1">`OrganizationIdentifier`</span>, investigation of this field shows that it is a map of integer to organization, the map is not available to us.<br><br>
    To make use of this column a value of 0.0 is added when no organization is present and all NaN values are replaced with it.<br><br>
    All other columns are dropped at this point, including those identified by the correlation chart, and then any row with missing data is dropped to clean all the remaining NaN values.<br><br>
    The visualization below shows the reduction in viable data as columns and NaN values are dropped. 
        <table>
          <tr>
            <th>Data Reduction</th>
          </tr>
          <tr>
            <td><span markdown="1">![data_reduction](../../../../../assets/malware_blog/output_31_1.png)</span></td>            
          </tr>
        </table>
    At this point all missing data issues have been resolved and creation of a model can begin. 
    </p>
</details>

<br>

<details><summary><strong>Data Modelling</strong></summary>
   
</details>

<br>

<details><summary><strong>Model Results and Evaluation</strong></summary>
    <p>
        Results of model go here, evaluation of model performance
    </p>
</details>

<br>

<details><summary><strong>Conclusion</strong></summary>
    <p>
        Conclusion statement and possible improvements go here
    </p>
</details>
